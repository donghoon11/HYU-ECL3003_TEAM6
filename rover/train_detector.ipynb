{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "649e6066",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa50bef",
   "metadata": {},
   "source": [
    "## Setup environment\n",
    "\n",
    "### (Optional) If you are on google colab,\n",
    "\n",
    "- Visit google drive (https://drive.google.com)\n",
    "- Create a folder (example: hyu)\n",
    "- Upload this entire folder (i.e., HYU-ECL3003) to the folder\n",
    "- Open `train_detector.ipynb` on google drive (this action will open google colab session)\n",
    "- Switch runtime to `T4 GPU`\n",
    "\n",
    "\n",
    "### Common settings\n",
    "\n",
    "```bash\n",
    "$ python3 -m venv venv/ecl3003\n",
    "$ source venv/ecl3003/bin/activate\n",
    "$ pip install -r rover/requirements.txt\n",
    "```\n",
    "\n",
    "### Download your dataset from CVAT \n",
    "```bash\n",
    "$ mkdir -p ../../datasets\n",
    "$ unzip -d  ../../datasets/ ECL3003-dataset.zip \n",
    "```\n",
    "\n",
    "### Set validation set (or you can set train.txt for testing)\n",
    "```bash\n",
    "$ echo \"val: train.txt\" >> ../../datasets/data.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b4d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### (Optional) If you are on google colab,\n",
    "\n",
    "# # Mount google drive\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive/')\n",
    "\n",
    "# # Move to the new directory\n",
    "# cd /content/drive/MyDrive/hyu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75c7717",
   "metadata": {},
   "source": [
    "# Extract images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8751f7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "capture = cv2.VideoCapture(\"test_video.avi\")\n",
    "assert capture.isOpened(), \"Cannot open the video file.\"\n",
    "\n",
    "num_frames = int(capture.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Prepare folders\n",
    "img_filename_fmt = 'data/images/train/frame_{:06d}.png'\n",
    "dirname = os.path.dirname(img_filename_fmt)\n",
    "os.makedirs(dirname, exist_ok=True)\n",
    "\n",
    "for ii in range(num_frames):\n",
    "    _, frame = capture.read()\n",
    "    cv2.imwrite(img_filename_fmt.format(ii), frame)\n",
    "\n",
    "capture.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2efbb",
   "metadata": {},
   "source": [
    "# Make a symbolic link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6652aad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.symlink('../../../datasets/labels', 'data/labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4e81fc",
   "metadata": {},
   "source": [
    "# Train a YOLO model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c6f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a pretrained YOLO11n model\n",
    "model = YOLO(\"yolo11n.pt\")\n",
    "\n",
    "# Train the model on the COCO8 dataset for 100 epochs\n",
    "train_results = model.train(\n",
    "    data=\"../../datasets/data.yaml\",  # Path to dataset configuration file\n",
    "    epochs=200,  # Number of training epochs\n",
    "    imgsz=640,  # Image size for training\n",
    "    device=0,  # Device to run on (e.g., 'cpu', 0, [0,1,2,3])\n",
    "    optimizer='Adam',\n",
    "    lr0=1e-2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f77ae973",
   "metadata": {},
   "source": [
    "# Make an inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9615e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance on the validation set\n",
    "metrics = model.val()\n",
    "\n",
    "# Perform object detection on an image\n",
    "results = model(\"data/images/train/frame_000000.png\")  # Predict on an image\n",
    "results[0].show()  # Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95163946",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # Export the model to ONNX format for deployment\n",
    "# path = model.export(format=\"onnx\")  # Returns the path to the exported model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
